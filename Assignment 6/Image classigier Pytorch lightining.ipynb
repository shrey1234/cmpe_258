{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image classigier Pytorch lightining.ipynb","provenance":[],"authorship_tag":"ABX9TyMUYTH8I9Wm1bWyHHI117u6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"20c28c3e41374ccc95c148599f424734":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_284db5c0d2414c488022c8c7f52085d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b55eb555082b470480ee106009b75ed5","IPY_MODEL_de5a82d3fcd3491f9e5c2fa8a31eb496"]}},"284db5c0d2414c488022c8c7f52085d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b55eb555082b470480ee106009b75ed5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b6c9aa7d8f64815b9b58f77ad4932c8","_dom_classes":[],"description":"Epoch 1:   0%","_model_name":"FloatProgressModel","bar_style":"info","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1947f5ece1374cbe8a41dcd9beb25c08"}},"de5a82d3fcd3491f9e5c2fa8a31eb496":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dbfa07c54d90491db56fe66b58e9c240","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/10 [00:00&lt;?, ?it/s, loss=-0.317, v_num=37]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07e5404650e9403fb435ba95acd4e1f3"}},"4b6c9aa7d8f64815b9b58f77ad4932c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1947f5ece1374cbe8a41dcd9beb25c08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbfa07c54d90491db56fe66b58e9c240":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07e5404650e9403fb435ba95acd4e1f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2J6BiQoAP3aN","executionInfo":{"status":"ok","timestamp":1619401061666,"user_tz":420,"elapsed":32348,"user":{"displayName":"Shreya Goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVsl18G8XwoIr9Ou5nfrZdpmwxA-g-n7XxqlSX=s64","userId":"05010597830317148669"}},"outputId":"659967f7-0806-4f9a-87b4-ddfd13bc7948"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jafItRiaYvbg"},"source":["!pip install pytorch-lightning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GRsH2htyYo7j","executionInfo":{"status":"ok","timestamp":1619414881643,"user_tz":420,"elapsed":898,"user":{"displayName":"Shreya Goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVsl18G8XwoIr9Ou5nfrZdpmwxA-g-n7XxqlSX=s64","userId":"05010597830317148669"}}},"source":["# import module\n","import torch \n","  \n","# To get the layers and losses for our model\n","from torch import nn \n","import pytorch_lightning as pl \n","  \n","# To get the activation function for our model\n","import torch.nn.functional as F \n","  \n","# To get MNIST data and transforms\n","from torchvision import datasets, transforms\n","  \n","# To get the optimizer for our model\n","from torch.optim import SGD \n","  \n","\n","from torch.utils.data import random_split, DataLoader "],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"muhHbhDGZb5b","executionInfo":{"status":"ok","timestamp":1619414910556,"user_tz":420,"elapsed":489,"user":{"displayName":"Shreya Goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVsl18G8XwoIr9Ou5nfrZdpmwxA-g-n7XxqlSX=s64","userId":"05010597830317148669"}}},"source":["\n","class DataModuleMNIST(pl.LightningDataModule):\n","    def __init__(self):\n","        super().__init__()\n","          \n","        # Directory to store MNIST Data\n","        self.download_dir = '/content/drive/MyDrive/258/Assignment 6/Dataset'\n","          \n","        # Defining batch size of our data\n","        self.batch_size = 32\n","          \n","        # Defining transforms to be applied on the data\n","        self.transform = transforms.Compose([transforms.Resize((224,244)),transforms.ToTensor()])\n","\n","    def collate_fn(data):\n","      img, bbox = data\n","      zipped = zip(img, bbox)\n","      return list(zipped)\n","\n","    def prepare_data(self):\n","        print(\"shreya\")\n","        \n","    def setup(self, stage=None):\n","        \n","        \n","      data = datasets.ImageFolder(self.download_dir, transform = self.transform)\n","      self.train_data, self.valid_data, self.test_data = random_split(data, [316, 100, 100])\n","      self.train_data.dataset.transform = self.transform\n","      self.valid_data.dataset.transform = self.transform\n","      self.test_data.dataset.transform = self.transform\n","\n","    def train_dataloader(self):\n","        \n","          # Generating train_dataloader\n","        return DataLoader(self.train_data, \n","                          batch_size = self.batch_size)\n","  \n","    def val_dataloader(self):\n","        \n","          # Generating val_dataloader\n","        return DataLoader(self.valid_data,\n","                          batch_size = self.batch_size)\n","  \n","    def test_dataloader(self):\n","        \n","        # Generating test_dataloader\n","        return DataLoader(self.test_data,\n","                          batch_size = self.batch_size)"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q23mcVhyZrFF","executionInfo":{"status":"ok","timestamp":1619416084108,"user_tz":420,"elapsed":641,"user":{"displayName":"Shreya Goyal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjVsl18G8XwoIr9Ou5nfrZdpmwxA-g-n7XxqlSX=s64","userId":"05010597830317148669"}}},"source":["class model(pl.LightningModule): \n","    def __init__(self): \n","        \n","\n","      super(model, self).__init__()\n","      #print(\"inside model\")\n","      self.layer1 = torch.nn.Sequential(\n","          torch.nn.Conv2d(3,28,kernel_size=5),\n","          torch.nn.ReLU(),\n","          torch.nn.MaxPool2d(kernel_size=2))\n","      self.layer2 = torch.nn.Sequential(\n","          torch.nn.Conv2d(28,3,kernel_size=2),\n","          torch.nn.ReLU(),\n","          torch.nn.MaxPool2d(kernel_size=2))\n","\n","      self.dropout1=torch.nn.Dropout(0.25)\n","      self.fc1=torch.nn.Linear(9558,5000)\n","      self.dropout2=torch.nn.Dropout(0.08)\n","      self.fc2=torch.nn.Linear(5000,3)\n","\n","    def forward(self, x):\n","      #print(\"inside forward\")\n","      x=self.layer1(x)\n","      x=self.layer2(x)\n","      x=self.dropout1(x)\n","      x=torch.relu(self.fc1(x.view(x.size(0), -1)))\n","      x=F.leaky_relu(self.dropout2(x))\n","      return F.softmax(self.fc2(x))\n","\n","    \n","    def configure_optimizers(self):\n","      return torch.optim.Adam(self.parameters())\n","\n","    def training_step(self, train_batch, batch_idx): \n","      #print(\"inside training loop\")\n","      x,labels=train_batch\n","      #print(x.shape)\n","      #print(labels.shape)\n","      #doing a forward pass\n","      pred=self.forward(x)\n","      #calculating the loss\n","      loss = F.nll_loss(pred, labels)     \n","      #logs\n","      logs={\n","          \"train_loss\": loss}\n","      output={\n","          #REQUIRED: It ie required for us to return \"loss\"\n","          \"loss\": loss,\n","          #optional for logging purposes\n","          \"log\": logs\n","      }\n","      return output\n","       \n","    \n","    # def validation_step(self, valid_batch, batch_idx): \n","        \n","    #     # Defining validation steps for our model\n","    #     x, y = valid_batch \n","    #     logits = self.forward(x) \n","    #     loss = self.loss(logits, y)"],"execution_count":104,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528,"referenced_widgets":["20c28c3e41374ccc95c148599f424734","284db5c0d2414c488022c8c7f52085d0","b55eb555082b470480ee106009b75ed5","de5a82d3fcd3491f9e5c2fa8a31eb496","4b6c9aa7d8f64815b9b58f77ad4932c8","1947f5ece1374cbe8a41dcd9beb25c08","dbfa07c54d90491db56fe66b58e9c240","07e5404650e9403fb435ba95acd4e1f3"]},"id":"cHLUGZUEZuf8","outputId":"b1308512-4a72-4c11-9c40-d1d8904171a0"},"source":["clf = model() \n","mnist = DataModuleMNIST() \n","trainer = pl.Trainer()\n","trainer.fit(clf, mnist)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping validation loop\n","  warnings.warn(*args, **kwargs)\n","\n","  | Name     | Type       | Params\n","----------------------------------------\n","0 | layer1   | Sequential | 2.1 K \n","1 | layer2   | Sequential | 339   \n","2 | dropout1 | Dropout    | 0     \n","3 | fc1      | Linear     | 47.8 M\n","4 | dropout2 | Dropout    | 0     \n","5 | fc2      | Linear     | 15.0 K\n","----------------------------------------\n","47.8 M    Trainable params\n","0         Non-trainable params\n","47.8 M    Total params\n","191.250   Total estimated model params size (MB)\n"],"name":"stderr"},{"output_type":"stream","text":["shreya\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"20c28c3e41374ccc95c148599f424734","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0\n","Please use self.log(...) inside the lightningModule instead.\n","# log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)\n","self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n","  warnings.warn(*args, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"}]}]}